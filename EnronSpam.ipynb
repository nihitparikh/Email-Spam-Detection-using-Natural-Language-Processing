{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data set from here: http://www.aueb.gr/users/ion/data/enron-spam/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"Enron\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron ['enron1', 'enron6', 'enron5', 'enron2', 'enron3', 'enron4'] 1\n",
      "Enron/enron1 ['spam', 'ham'] 2\n",
      "Enron/enron1/spam [] 1499\n",
      "Enron/enron1/ham [] 3672\n",
      "Enron/enron6 ['spam', 'ham'] 1\n",
      "Enron/enron6/spam [] 4500\n",
      "Enron/enron6/ham [] 1500\n",
      "Enron/enron5 ['spam', 'ham'] 1\n",
      "Enron/enron5/spam [] 3675\n",
      "Enron/enron5/ham [] 1500\n",
      "Enron/enron2 ['spam', 'ham'] 1\n",
      "Enron/enron2/spam [] 1496\n",
      "Enron/enron2/ham [] 4361\n",
      "Enron/enron3 ['spam', 'ham'] 1\n",
      "Enron/enron3/spam [] 1500\n",
      "Enron/enron3/ham [] 4012\n",
      "Enron/enron4 ['spam', 'ham'] 1\n",
      "Enron/enron4/spam [] 4500\n",
      "Enron/enron4/ham [] 1500\n"
     ]
    }
   ],
   "source": [
    "# Loop through all the directories, sub directories and files in the above folder, and print them.\n",
    "\n",
    "# For files, print number of files.\n",
    "\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    print(directories, subdirs, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'Enron Spam\\\\enron1\\\\ham')\n",
      "\n",
      "Enron Spam\\enron1\\ham\n"
     ]
    }
   ],
   "source": [
    "print(os.path.split(\"Enron Spam\\\\enron1\\\\ham\"))\n",
    "print(os.path.split(\"Enron Spam\\\\enron1\\\\ham\")[0])\n",
    "print(os.path.split(\"Enron Spam\\\\enron1\\\\ham\")[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron/enron1/spam [] 1499\n",
      "Enron/enron1/ham [] 3672\n",
      "Enron/enron6/spam [] 4500\n",
      "Enron/enron6/ham [] 1500\n",
      "Enron/enron5/spam [] 3675\n",
      "Enron/enron5/ham [] 1500\n",
      "Enron/enron2/spam [] 1496\n",
      "Enron/enron2/ham [] 4361\n",
      "Enron/enron3/spam [] 1500\n",
      "Enron/enron3/ham [] 4012\n",
      "Enron/enron4/spam [] 4500\n",
      "Enron/enron4/ham [] 1500\n"
     ]
    }
   ],
   "source": [
    "# Same as before, but only print the ham and spam folders\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    if (os.path.split(directories)[1]  == 'ham'):\n",
    "        print(directories, subdirs, len(files))\n",
    "    \n",
    "    if (os.path.split(directories)[1]  == 'spam'):\n",
    "        print(directories, subdirs, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: ena sales on hpl\n",
      "just to update you on this project ' s status :\n",
      "based on a new report that scott mills ran for me from sitara , i have come up\n",
      "with the following counterparties as the ones to which ena is selling gas off\n",
      "of hpl ' s pipe .\n",
      "altrade transaction , l . l . c . gulf gas utilities company\n",
      "brazoria , city of panther pipeline , inc .\n",
      "central illinois light company praxair , inc .\n",
      "central power and light company reliant energy - entex\n",
      "ces - equistar chemicals , lp reliant energy - hl & p\n",
      "corpus christi gas marketing , lp southern union company\n",
      "d & h gas company , inc . texas utilities fuel company\n",
      "duke energy field services , inc . txu gas distribution\n",
      "entex gas marketing company union carbide corporation\n",
      "equistar chemicals , lp unit gas transmission company inc .\n",
      "since i ' m not sure exactly what gets entered into sitara , pat clynes\n",
      "suggested that i check with daren farmer to make sure that i ' m not missing\n",
      "something ( which i did below ) . while i am waiting for a response from him\n",
      "and / or mary smith , i will begin gathering the contractual volumes under the\n",
      "above contracts .\n",
      "- - - - - - - - - - - - - - - - - - - - - - forwarded by cheryl dudley / hou / ect on 05 / 10 / 2000 07 : 56\n",
      "am - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "cheryl d king\n",
      "05 / 08 / 2000 04 : 11 pm\n",
      "sent by : cheryl dudley\n",
      "to : daren j farmer / hou / ect @ ect , mary m smith / hou / ect @ ect\n",
      "cc :\n",
      "subject : ena sales on hpl\n",
      "i am working on a project for brenda herod & was wondering if one of you\n",
      "could tell me if i ' m on the right track & if this will get everything for\n",
      "which she is looking .\n",
      "she is trying to draft a long - term transport / storage agreement between ena &\n",
      "hplc which will allow ena to move the gas to their markets . in order to\n",
      "accomplish this , she needs to know all of the sales to customers that ena is\n",
      "doing off of hpl ' s pipe .\n",
      "i had scott mills run a report from sitara showing all ena buy / sell activity\n",
      "on hpl since 7 / 99 . if i eliminate the buys & the desk - to - desk deals , will\n",
      "this give me everything that i need ?\n",
      "are there buy / sell deals done with ena on hpl ' s pipe that wouldn ' t show up in\n",
      "sitara ? someone mentioned something about deals where hpl transports the gas\n",
      "on it ' s own behalf then ena sells it to a customer at that same spot - -\n",
      "? ? ? ? ? do deals like that happen ? would they show up in sitara ?\n",
      "is there anything else that i ' m missing ? i ' m not real familiar with how some\n",
      "of these deals happen nowadays so am very receptive to any\n",
      "ideas / suggestions / help that you can offer ! ! !\n",
      "thanks in advance .\n",
      "Subject: what up , , your cam babe\n",
      "what are you looking for ?\n",
      "if your looking for a companion for friendship , love , a date , or just good ole '\n",
      "fashioned * * * * * * , then try our brand new site ; it was developed and created\n",
      "to help anyone find what they ' re looking for . a quick bio form and you ' re\n",
      "on the road to satisfaction in every sense of the word . . . . no matter what\n",
      "that may be !\n",
      "try it out and youll be amazed .\n",
      "have a terrific time this evening\n",
      "copy and pa ste the add . ress you see on the line below into your browser to come to the site .\n",
      "http : / / www . meganbang . biz / bld / acc /\n",
      "no more plz\n",
      "http : / / www . naturalgolden . com / retract /\n",
      "counterattack aitken step preemptive shoehorn scaup . electrocardiograph movie honeycomb . monster war brandywine pietism byrne catatonia . encomia lookup intervenor skeleton turn catfish .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ham_list = []\n",
    "spam_list = []\n",
    "\n",
    "# Same as before, but this time, read the files, and append them to the ham and spam list\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    if (os.path.split(directories)[1]  == 'ham'):\n",
    "        for filename in files:      \n",
    "            with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                data = f.read()\n",
    "                ham_list.append(data)\n",
    "    \n",
    "    if (os.path.split(directories)[1]  == 'spam'):\n",
    "        for filename in files:\n",
    "            with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                data = f.read()\n",
    "                spam_list.append(data)\n",
    "\n",
    "\n",
    "print(ham_list[0])\n",
    "print(spam_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3 Encodings: http://python-notes.curiousefficiency.org/en/latest/python3/text_file_processing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True, 'quick': True, 'brown': True, 'a': True, 'fox': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function , that when passed in words, will return a dictionary of the form\n",
    "\n",
    "# {Word1: True, Word2: True, Words3: True}\n",
    "\n",
    "# Removing stop words is optional\n",
    "\n",
    "def create_word_features(words):\n",
    "    my_dict = dict( [ (word, True) for word in words] )\n",
    "    return my_dict\n",
    "\n",
    "create_word_features([\"the\", \"quick\", \"brown\", \"quick\", \"a\", \"fox\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'Subject': True, ':': True, 'ena': True, 'sales': True, 'on': True, 'hpl': True, 'just': True, 'to': True, 'update': True, 'you': True, 'this': True, 'project': True, \"'\": True, 's': True, 'status': True, 'based': True, 'a': True, 'new': True, 'report': True, 'that': True, 'scott': True, 'mills': True, 'ran': True, 'for': True, 'me': True, 'from': True, 'sitara': True, ',': True, 'i': True, 'have': True, 'come': True, 'up': True, 'with': True, 'the': True, 'following': True, 'counterparties': True, 'as': True, 'ones': True, 'which': True, 'is': True, 'selling': True, 'gas': True, 'off': True, 'of': True, 'pipe': True, '.': True, 'altrade': True, 'transaction': True, 'l': True, 'c': True, 'gulf': True, 'utilities': True, 'company': True, 'brazoria': True, 'city': True, 'panther': True, 'pipeline': True, 'inc': True, 'central': True, 'illinois': True, 'light': True, 'praxair': True, 'power': True, 'and': True, 'reliant': True, 'energy': True, '-': True, 'entex': True, 'ces': True, 'equistar': True, 'chemicals': True, 'lp': True, 'hl': True, '&': True, 'p': True, 'corpus': True, 'christi': True, 'marketing': True, 'southern': True, 'union': True, 'd': True, 'h': True, 'texas': True, 'fuel': True, 'duke': True, 'field': True, 'services': True, 'txu': True, 'distribution': True, 'carbide': True, 'corporation': True, 'unit': True, 'transmission': True, 'since': True, 'm': True, 'not': True, 'sure': True, 'exactly': True, 'what': True, 'gets': True, 'entered': True, 'into': True, 'pat': True, 'clynes': True, 'suggested': True, 'check': True, 'daren': True, 'farmer': True, 'make': True, 'missing': True, 'something': True, '(': True, 'did': True, 'below': True, ')': True, 'while': True, 'am': True, 'waiting': True, 'response': True, 'him': True, '/': True, 'or': True, 'mary': True, 'smith': True, 'will': True, 'begin': True, 'gathering': True, 'contractual': True, 'volumes': True, 'under': True, 'above': True, 'contracts': True, 'forwarded': True, 'by': True, 'cheryl': True, 'dudley': True, 'hou': True, 'ect': True, '05': True, '10': True, '2000': True, '07': True, '56': True, 'king': True, '08': True, '04': True, '11': True, 'pm': True, 'sent': True, 'j': True, '@': True, 'cc': True, 'subject': True, 'working': True, 'brenda': True, 'herod': True, 'was': True, 'wondering': True, 'if': True, 'one': True, 'could': True, 'tell': True, 'right': True, 'track': True, 'get': True, 'everything': True, 'she': True, 'looking': True, 'trying': True, 'draft': True, 'long': True, 'term': True, 'transport': True, 'storage': True, 'agreement': True, 'between': True, 'hplc': True, 'allow': True, 'move': True, 'their': True, 'markets': True, 'in': True, 'order': True, 'accomplish': True, 'needs': True, 'know': True, 'all': True, 'customers': True, 'doing': True, 'had': True, 'run': True, 'showing': True, 'buy': True, 'sell': True, 'activity': True, '7': True, '99': True, 'eliminate': True, 'buys': True, 'desk': True, 'deals': True, 'give': True, 'need': True, '?': True, 'are': True, 'there': True, 'done': True, 'wouldn': True, 't': True, 'show': True, 'someone': True, 'mentioned': True, 'about': True, 'where': True, 'transports': True, 'it': True, 'own': True, 'behalf': True, 'then': True, 'sells': True, 'customer': True, 'at': True, 'same': True, 'spot': True, 'do': True, 'like': True, 'happen': True, 'would': True, 'they': True, 'anything': True, 'else': True, 'real': True, 'familiar': True, 'how': True, 'some': True, 'these': True, 'nowadays': True, 'so': True, 'very': True, 'receptive': True, 'any': True, 'ideas': True, 'suggestions': True, 'help': True, 'can': True, 'offer': True, '!': True, 'thanks': True, 'advance': True}, 'ham')\n",
      "({'Subject': True, ':': True, 'what': True, 'up': True, ',': True, 'your': True, 'cam': True, 'babe': True, 'are': True, 'you': True, 'looking': True, 'for': True, '?': True, 'if': True, 'a': True, 'companion': True, 'friendship': True, 'love': True, 'date': True, 'or': True, 'just': True, 'good': True, 'ole': True, \"'\": True, 'fashioned': True, '*': True, 'then': True, 'try': True, 'our': True, 'brand': True, 'new': True, 'site': True, ';': True, 'it': True, 'was': True, 'developed': True, 'and': True, 'created': True, 'to': True, 'help': True, 'anyone': True, 'find': True, 'they': True, 're': True, '.': True, 'quick': True, 'bio': True, 'form': True, 'on': True, 'the': True, 'road': True, 'satisfaction': True, 'in': True, 'every': True, 'sense': True, 'of': True, 'word': True, 'no': True, 'matter': True, 'that': True, 'may': True, 'be': True, '!': True, 'out': True, 'youll': True, 'amazed': True, 'have': True, 'terrific': True, 'time': True, 'this': True, 'evening': True, 'copy': True, 'pa': True, 'ste': True, 'add': True, 'ress': True, 'see': True, 'line': True, 'below': True, 'into': True, 'browser': True, 'come': True, 'http': True, '/': True, 'www': True, 'meganbang': True, 'biz': True, 'bld': True, 'acc': True, 'more': True, 'plz': True, 'naturalgolden': True, 'com': True, 'retract': True, 'counterattack': True, 'aitken': True, 'step': True, 'preemptive': True, 'shoehorn': True, 'scaup': True, 'electrocardiograph': True, 'movie': True, 'honeycomb': True, 'monster': True, 'war': True, 'brandywine': True, 'pietism': True, 'byrne': True, 'catatonia': True, 'encomia': True, 'lookup': True, 'intervenor': True, 'skeleton': True, 'turn': True, 'catfish': True}, 'spam')\n"
     ]
    }
   ],
   "source": [
    "ham_list = []\n",
    "spam_list = []\n",
    "\n",
    "# Same as before, but this time:\n",
    "\n",
    "# 1. Break the sentences into words using word_tokenize\n",
    "# 2. Use the create_word_features() function you just wrote\n",
    "for directories, subdirs, files in os.walk(rootdir):\n",
    "    if (os.path.split(directories)[1]  == 'ham'):\n",
    "        for filename in files:      \n",
    "            with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                data = f.read()\n",
    "                \n",
    "                # The data we read is one big string. We need to break it into words.\n",
    "                words = word_tokenize(data)\n",
    "                \n",
    "                ham_list.append((create_word_features(words), \"ham\"))\n",
    "    \n",
    "    if (os.path.split(directories)[1]  == 'spam'):\n",
    "        for filename in files:\n",
    "            with open(os.path.join(directories, filename), encoding=\"latin-1\") as f:\n",
    "                data = f.read()\n",
    "                \n",
    "                # The data we read is one big string. We need to break it into words.\n",
    "                words = word_tokenize(data)\n",
    "                if(words!=\"Congratulations\" or words!=\"congratulations\" or words!=\"CONGRATUALTIONS\"):\n",
    "                    spam_list.append((create_word_features(words), \"spam\"))\n",
    "print(ham_list[0])\n",
    "print(spam_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33715\n"
     ]
    }
   ],
   "source": [
    "combined_list = ham_list + spam_list\n",
    "print(len(combined_list))\n",
    "\n",
    "random.shuffle(combined_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33715\n",
      "23600\n",
      "10115\n"
     ]
    }
   ],
   "source": [
    "# Create a test and train section.\n",
    "\n",
    "# 70% of the data is training. 30% is test\n",
    "\n",
    "training_part = int(len(combined_list) * .7)\n",
    "\n",
    "print(len(combined_list))\n",
    "\n",
    "training_set = combined_list[:training_part]\n",
    "\n",
    "test_set =  combined_list[training_part:]\n",
    "\n",
    "print (len(training_set))\n",
    "print (len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is:  98.5664854176965\n"
     ]
    }
   ],
   "source": [
    "# Create the Naive Bayes filter\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Find the accuracy, using the test data\n",
    "\n",
    "accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
    "\n",
    "print(\"Accuracy is: \", accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   enron = True              ham : spam   =   3581.3 : 1.0\n",
      "                     php = True             spam : ham    =    430.3 : 1.0\n",
      "                 parsing = True              ham : spam   =    346.2 : 1.0\n",
      "                     sex = True             spam : ham    =    325.4 : 1.0\n",
      "                    meds = True             spam : ham    =    301.5 : 1.0\n",
      "                  louise = True              ham : spam   =    283.8 : 1.0\n",
      "                     xls = True              ham : spam   =    283.1 : 1.0\n",
      "                 stinson = True              ham : spam   =    265.2 : 1.0\n",
      "                     ect = True              ham : spam   =    252.2 : 1.0\n",
      "              scheduling = True              ham : spam   =    216.3 : 1.0\n",
      "             medications = True             spam : ham    =    211.4 : 1.0\n",
      "                     eol = True              ham : spam   =    205.5 : 1.0\n",
      "              macromedia = True             spam : ham    =    197.8 : 1.0\n",
      "                     713 = True              ham : spam   =    196.8 : 1.0\n",
      "                     hpl = True              ham : spam   =    187.0 : 1.0\n",
      "               schedules = True              ham : spam   =    186.6 : 1.0\n",
      "                       \u0001 = True              ham : spam   =    175.3 : 1.0\n",
      "                     oem = True             spam : ham    =    170.0 : 1.0\n",
      "                    pill = True             spam : ham    =    163.5 : 1.0\n",
      "                    memo = True              ham : spam   =    153.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg1 = '''Congratulations varun for getting selected in the team. The training starts from monday 10 am. Looking forward to work with you'''\n",
    "\n",
    "msg2 = '''This is to inform all the students to remain present in the class after 4 pm for a special announcement'''\n",
    "\n",
    "msg3 = '''As one of our top customers we are providing 10% OFF the total of your next used book purchase from www.letthestoriesliveon.com. Please use the promotional code, TOPTENOFF at checkout. Limited to 1 use per customer. All books have free shipping within the contiguous 48 United States and there is no minimum purchase.\n",
    "\n",
    "We have millions of used books in stock that are up to 90% off MRSP and add tens of thousands of new items every day. Don’t forget to check back frequently for new arrivals.'''\n",
    "\n",
    "msg4 = '''To start off, I have a 6 new videos + transcripts in the members section. In it, we analyse the Enron email dataset, half a million files, spread over 2.5GB. It's about 1.5 hours of  video.\n",
    "\n",
    "I have also created a Conda environment for running the code (both free and member lessons). This is to ensure everyone is running the same version of libraries, preventing the Works on my machine problems. If you get a second, do you mind trying it here?'''\n",
    "\n",
    "msg5 = '''Sir, we are honourably seeking your assistance in the following ways.\n",
    "        1) To provide a Bank account where this money would be transferred to.\n",
    "        2) To serve as the guardian of this since I am a girl of 26 years.\n",
    "        Moreover Sir, we are willing to offer you 15% of the sum as compensation for effort input after the successful transfer of this fund to your designate account overseas. please feel free to contact ,me via this email address\n",
    "        wumi1000abdul@yahoo.comAnticipating to hear from you soon.Thanks and God Bless.'''\n",
    "\n",
    "msg6 = '''I've mentioned that Python is widely used for data pre-processing tasks. \n",
    "        Here's a really nice use of Python for preparing flight data for plotting in Tableau. \n",
    "        The same principles can be used for plotting all kinds of geographic related \"routes\". \n",
    "        Plus, you learn about KML files and working with spatial data.'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Congratulations', 'varun', 'for', 'getting', 'selected', 'in', 'the', 'team', '.', 'The', 'training', 'starts', 'from', 'monday', '10', 'am', '.', 'Looking', 'forward', 'to', 'work', 'with', 'you']\n",
      "Message 1 is : ham\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg1)\n",
    "print(words)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 1 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 2 is : ham\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg2)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 2 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 3 is : spam\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg3)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 3 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 4 is : ham\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg4)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 4 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 5 is : spam\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg5)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 5 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 6 is : ham\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(msg6)\n",
    "features = create_word_features(words)\n",
    "print(\"Message 6 is :\" ,classifier.classify(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
